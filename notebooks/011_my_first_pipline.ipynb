{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp my_first_pipline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import hiddenlayer as hl\n",
    "from torchsummary import summary\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dataset():\n",
    "    root =str((Path.cwd().parent / \"data\").absolute())\n",
    "    transform = torch_geometric.transforms.ToUndirected()  # Add reverse edge types.\n",
    "\n",
    "    dataset = OGB_MAG(root=root, preprocess='metapath2vec', transform=transform)\n",
    "    return dataset\n",
    "\n",
    "def get_train_data_loader():\n",
    "    dataset = get_dataset()\n",
    "    data = dataset[0]\n",
    "    train_loader = torch_geometric.loader.NeighborLoader(\n",
    "        data,\n",
    "        # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "        num_neighbors=[15] * 1,\n",
    "        # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "        batch_size=1,\n",
    "        input_nodes=('paper', data['paper'].train_mask),\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)  #.jittable()\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)  #.jittable()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_data_loader()\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in batch.x_dict.items():\n",
    "    print(f\"type input name:{key}, shape of tensor : {list(val.size())}\")\n",
    "for key, val in batch.edge_index_dict.items():\n",
    "    print(f\"type input name:{key}, shape of tensor : {list(val.size())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[38;5;241m=\u001b[39m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GNN(hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m to_hetero(model, batch\u001b[38;5;241m.\u001b[39mmetadata(), aggr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToUndirected()  \u001b[38;5;66;03m# Add reverse edge types.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m OGB_MAG(root\u001b[38;5;241m=\u001b[39mroot, preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetapath2vec\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToUndirected()  \u001b[38;5;66;03m# Add reverse edge types.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m OGB_MAG(root\u001b[38;5;241m=\u001b[39mroot, preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetapath2vec\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1179\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:620\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1095\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1053\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001b[0m, in \u001b[0;36mstop\u001b[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001b[0m\n\u001b[1;32m    167\u001b[0m     frame \u001b[38;5;241m=\u001b[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame:\n\u001b[0;32m--> 169\u001b[0m         \u001b[43mmain_debugger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1160\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_id)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1175\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_mpl_hook()\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 1175\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset=get_dataset()\n",
    "model = GNN(hidden_channels=64, out_channels=dataset.num_classes)\n",
    "model = to_hetero(model, batch.metadata(), aggr='sum')\n",
    "with torch.no_grad():  # Initialize lazy modules\n",
    "    out = model(batch.x_dict, batch.edge_index_dict)\n",
    "a = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def save_model_simple(py_model: torch.nn.Module):\n",
    "#     torch.save(py_model.state_dict(), \"shmira_sd.h5\")\n",
    "#     torch.save(py_model.state_dict(), \"shmira_sd.pt\")\n",
    "#     torch.save(py_model, \"shmira.h5\")\n",
    "#     torch.save(py_model, \"shmira.pt\")\n",
    "#\n",
    "# a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ts = torch.jit.script(model)\n",
    "# with torch.no_grad():  # Initialize lazy modules.\n",
    "#     out = model_ts(batch.x_dict, batch.edge_index_dict)\n",
    "# torch.save(model_ts.state_dict(),\"shmira_ts_sd.h5\")\n",
    "# torch.save(model_ts.state_dict(),\"shmira_ts_sd.pt\")\n",
    "# torch.save(model_ts,\"shmira_ts.h5\")\n",
    "# torch.save(model_ts,\"shmira_ts.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_core.ipynb.\n",
      "No export destination, ignored:\n",
      "#export\n",
      "import torch\n",
      "\n",
      "No export destination, ignored:\n",
      "\n",
      "#export\n",
      "def save_model_simple(py_model: torch.nn.Module):\n",
      "    torch.save(py_model.state_dict(), \"shmira_sd.h5\")\n",
      "    torch.save(py_model.state_dict(), \"shmira_sd.pt\")\n",
      "    torch.save(py_model, \"shmira.h5\")\n",
      "    torch.save(py_model, \"shmira.pt\")\n",
      "\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# export\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook2script; \u001b[43mnotebook2script\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ram_dev/lib/python3.9/site-packages/nbdev/export.py:445\u001b[0m, in \u001b[0;36mnotebook2script\u001b[0;34m(fname, silent, to_dict, bare)\u001b[0m\n\u001b[1;32m    443\u001b[0m d \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m to_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    444\u001b[0m modules \u001b[38;5;241m=\u001b[39m create_mod_files(files, to_dict, bare\u001b[38;5;241m=\u001b[39mbare)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(files): d \u001b[38;5;241m=\u001b[39m \u001b[43m_notebook2script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_dict: \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: add_init(get_config()\u001b[38;5;241m.\u001b[39mpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib_path\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ram_dev/lib/python3.9/site-packages/nbdev/export.py:372\u001b[0m, in \u001b[0;36m_notebook2script\u001b[0;34m(fname, modules, silent, to_dict, bare)\u001b[0m\n\u001b[1;32m    370\u001b[0m code \u001b[38;5;241m=\u001b[39m _from_future_import(fname_out, flags, code, to_dict)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[43m_add2all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mf\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m mod\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mupdate({f: fname\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m names})\n\u001b[1;32m    374\u001b[0m code \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m +$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, code, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ram_dev/lib/python3.9/site-packages/nbdev/export.py:215\u001b[0m, in \u001b[0;36m_add2all\u001b[0;34m(fname, names, line_width)\u001b[0m\n\u001b[1;32m    213\u001b[0m tw \u001b[38;5;241m=\u001b[39m TextWrapper(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, initial_indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, subsequent_indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m11\u001b[39m, break_long_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    214\u001b[0m re_all \u001b[38;5;241m=\u001b[39m _re__all__def\u001b[38;5;241m.\u001b[39msearch(text)\n\u001b[0;32m--> 215\u001b[0m start,end \u001b[38;5;241m=\u001b[39m \u001b[43mre_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m(),re_all\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    216\u001b[0m text_all \u001b[38;5;241m=\u001b[39m tw\u001b[38;5;241m.\u001b[39mwrap(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext[start:end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text[end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: f\u001b[38;5;241m.\u001b[39mwrite(text[:start] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text_all) \u001b[38;5;241m+\u001b[39m text[end:])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from nbdev.export import notebook2script; notebook2script()\n",
    "#\n",
    "# notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
